{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFNj1PUiebPk"
   },
   "source": [
    "# Shallow MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smfDr0FSVGFM"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeF7wVUNZIfA"
   },
   "source": [
    "Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:39:04.533113Z",
     "start_time": "2020-09-21T09:38:57.075890Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3TwuRukzbMYt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:39:04.741659Z",
     "start_time": "2020-09-21T09:39:04.535240Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9XRb4CBCZHbO",
    "outputId": "cd6d0653-8073-45eb-b56e-62108a9d33d6"
   },
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "  print(\"No GPU found\")\n",
    "else:\n",
    "  print(\"GPU ready: {}\".format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0cCfVORVGFP"
   },
   "source": [
    "Import preprocessing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:39:04.810204Z",
     "start_time": "2020-09-21T09:39:04.784536Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../helper-modules\")\n",
    "from preprocessing_utils import read_in_data, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owrMb6t7VGFU"
   },
   "source": [
    "Read in the data to df_train, df_val and df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:39:40.105898Z",
     "start_time": "2020-09-21T09:39:04.818783Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KeFp32IJVGFU"
   },
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = read_in_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acwTGCFnVGFX"
   },
   "source": [
    "Create X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:40:01.668161Z",
     "start_time": "2020-09-21T09:39:40.108571Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bN8m6sg0VGFY"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = preprocess(\"MLP\", df_train, df_test, df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T15:46:00.889462Z",
     "start_time": "2020-08-22T15:46:00.874616Z"
    },
    "colab_type": "text",
    "id": "bUWYTLd3VGFc"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tz1pyrZVVGFd"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:17:18.689263Z",
     "start_time": "2020-08-24T10:17:18.684892Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZDT9H42OVGFd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from itertools import product\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5V_4tr5Vc3h"
   },
   "source": [
    "Enable seed setting for improved reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIw8YPxR0kgB"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "  SEED=seed\n",
    "\n",
    "  # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "\n",
    "  # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "  random.seed(SEED)\n",
    "\n",
    "  # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "  np.random.seed(SEED)\n",
    "\n",
    "  # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "  tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:40:01.722065Z",
     "start_time": "2020-09-21T09:39:35.513Z"
    }
   },
   "source": [
    "Extract number of classes (10 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = df_test[\"label\"].nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-z9TXSxQ5Yj"
   },
   "source": [
    "Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFAPmE_3pIQk"
   },
   "outputs": [],
   "source": [
    "def compile_model(hidden_layers_sizes=(1024,), act_function=\"relu\", dropout_rate=0.1, l_rate=0.001, reg='l2', opt_algo='adam'):\n",
    "    \"\"\"\n",
    "    Compiles a shallow MLP model with one hidden layer with the given hyperparameters.\n",
    "    \n",
    "    Hyperparameter options:\n",
    "    \n",
    "    hidden_layers_sizes : tuple with the number of neurons in the hidden layers\n",
    "    act_function : options include \"relu\", \"sigmoid\" and \"tanh\"\n",
    "    dropout_rate : a float with the rate of dropout to be applied to the fully connected layer\n",
    "    l_rate : a float with the learning rate\n",
    "    reg : string with the regularization type e.g. \"l2\"\n",
    "    opt_algo : the optimization algorithm, \"adam\" or \"sgd\"\n",
    "    \"\"\"  \n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Add hidden layers with dropout to prevent overfitting\n",
    "    for i, h in enumerate(hidden_layers_sizes):\n",
    "      if i == 0:\n",
    "        model.add(Dense(h, activation=act_function, input_shape=(1480,)))\n",
    "      else: \n",
    "        model.add(Dense(h, activation=act_function))\n",
    "      model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # LAST LAYER IS THE CLASSIFIER, THUS 12 POSSIBLE CLASSES\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=reg))\n",
    "\n",
    "    # Optimization algorithm\n",
    "    if opt_algo == 'adam':\n",
    "      opt = tf.keras.optimizers.Adam(learning_rate=l_rate)\n",
    "    elif opt_algo == 'sgd':\n",
    "      opt = tf.keras.optimizers.SGD(learning_rate=l_rate)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcN-0PM6-ne7"
   },
   "source": [
    "# Experiment: Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mSyydAU0Sxsj"
   },
   "source": [
    "Defining grid search hyperparameter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwl6l730Cxae"
   },
   "outputs": [],
   "source": [
    "hidden_layers_sizes = [(1,), (5,), (20,), (81,), (322,), (1288,)]\n",
    "l_rates = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "dropout_rates = [0.05, 0.1, 0.2, 0.5]\n",
    "act_functions=[\"relu\"]\n",
    "regs = ['l2']\n",
    "opt_algos = ['adam']\n",
    "\n",
    "all_hparams = [hidden_layers_sizes, l_rates, dropout_rates, act_functions, regs, opt_algos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9CsRRgZnS7DW"
   },
   "source": [
    "Conduct the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeoFhwpK8F_w"
   },
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "  \"\"\"\n",
    "  For each `hidden_layers_sizes` option (corresponding to a given number of parameters), conduct a grid search\n",
    "  over the hyperparameter options, writing the validation results and model details for each model to a file.\n",
    "  \n",
    "  All trained models are saved as h5 files. \n",
    "  \"\"\"\n",
    " \n",
    "  best_model = None\n",
    "  best_accuracy = 0\n",
    "  best_history = None\n",
    "\n",
    "  EPOCHS = 50\n",
    "  BATCH_SIZE = 32\n",
    "  STOPPING_PATIENCE = 5\n",
    "\n",
    "  STARTING_POINT = 1\n",
    "\n",
    "  with open('../training-results/ExperimentLogs_Shallow-MLP.csv', 'w') as log_file:\n",
    "      log_file.write(\"ModelNumber;Timestamp;NumEpochs;ValAccuracy;NumParams;HiddenLayerSizes;LearningRate;DropoutRate;ActivationFunction;Regularization;OptimizationAlgorithm\\n\")\n",
    "\n",
    "  for model_num, hparam_set in enumerate(list(product(*all_hparams))[0:], start=STARTING_POINT):\n",
    "    # Extract hyperparams for current model from grid search grid\n",
    "    hidden_layers_sizes_tup, l_rate, dropout_rate, act_function, reg, opt_algo = hparam_set\n",
    "\n",
    "    # Define hyperparameters for the current model \n",
    "    hparams = {\n",
    "        \"hidden_layers_sizes\" : hidden_layers_sizes_tup,\n",
    "        \"act_function\" : act_function, \n",
    "        \"dropout_rate\" : dropout_rate, \n",
    "        \"l_rate\": l_rate,\n",
    "        \"reg\" : reg,\n",
    "        \"opt_algo\" : opt_algo\n",
    "    }\n",
    "\n",
    "    # Compile model and count number of parameters\n",
    "    model = compile_model(**hparams)\n",
    "    num_params = model.count_params()\n",
    "\n",
    "    model_str = f\"{hidden_layers_sizes_tup}; {l_rate}; {dropout_rate}; {act_function}; {reg}; {opt_algo}\"\n",
    "    print(f\"Training model {model_num} with {num_params} params - {model_str}\")\n",
    "\n",
    "    # Prevent overfitting with early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=STOPPING_PATIENCE)\n",
    "    # For saving best val accuracy model as an h5 (for test predictions later)\n",
    "    model_check = ModelCheckpoint(f\"../trained-models/Shallow-MLP_{model_num}.h5\", monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(42)\n",
    "\n",
    "    # Train model\n",
    "    # Note: one reason val accuracy might be higher than train accuracy during training is because dropout affects training but not validation\n",
    "    history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), callbacks=[early_stop, model_check])\n",
    "    n_epochs = len(history.history['loss'])\n",
    "                   \n",
    "    # Time stamp when model finished training\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    # Extract best validation accuracy at inex 1 (index 0 has the loss)\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"Best val accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Store results in log file\n",
    "    with open('../training-results/ExperimentLogs_Shallow-MLP.csv', 'a') as log_file:\n",
    "      log_file.write(f\"{model_num};{timestamp};{n_epochs};{val_accuracy};{num_params};{model_str}\\n\")\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "      best_accuracy = val_accuracy\n",
    "      best_model = model\n",
    "      best_history = history\n",
    "\n",
    "  # Return the model with the highest validation accuracy\n",
    "  return best_model, best_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lHPXpkohzXrY",
    "outputId": "bb3102dc-2799-4485-fca7-9653b6247e70"
   },
   "outputs": [],
   "source": [
    "best_model, best_history = grid_search()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Experiments_Shallow-MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
