{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying Payload Size for Deep 2D-CNN Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smfDr0FSVGFM"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DeF7wVUNZIfA"
   },
   "source": [
    "Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:39:04.533113Z",
     "start_time": "2020-09-21T09:38:57.075890Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3TwuRukzbMYt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:39:04.741659Z",
     "start_time": "2020-09-21T09:39:04.535240Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9XRb4CBCZHbO",
    "outputId": "cd6d0653-8073-45eb-b56e-62108a9d33d6"
   },
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "  print(\"No GPU found\")\n",
    "else:\n",
    "  print(\"GPU ready: {}\".format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0cCfVORVGFP"
   },
   "source": [
    "Import preprocessing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:48:06.102351Z",
     "start_time": "2020-09-21T12:47:58.658255Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../helper-modules\")\n",
    "from preprocessing_utils import read_in_data, preprocess_varying_payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owrMb6t7VGFU"
   },
   "source": [
    "Read in the data to df_train, df_val and df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:48:43.521379Z",
     "start_time": "2020-09-21T12:48:19.799192Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KeFp32IJVGFU"
   },
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = read_in_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T15:46:00.889462Z",
     "start_time": "2020-08-22T15:46:00.874616Z"
    },
    "colab_type": "text",
    "id": "bUWYTLd3VGFc"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tz1pyrZVVGFd"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:17:18.689263Z",
     "start_time": "2020-08-24T10:17:18.684892Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZDT9H42OVGFd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, AvgPool2D, Flatten, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from itertools import product\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5V_4tr5Vc3h"
   },
   "source": [
    "Enable seed setting for improved reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIw8YPxR0kgB"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "  SEED=seed\n",
    "\n",
    "  # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "\n",
    "  # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "  random.seed(SEED)\n",
    "\n",
    "  # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "  np.random.seed(SEED)\n",
    "\n",
    "  # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "  tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T09:40:01.722065Z",
     "start_time": "2020-09-21T09:39:35.513Z"
    }
   },
   "source": [
    "Extract number of classes (10 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = df_test[\"label\"].nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-z9TXSxQ5Yj"
   },
   "source": [
    "Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T10:17:19.126353Z",
     "start_time": "2020-08-24T10:17:19.119966Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WvLFRXjyVGFh"
   },
   "outputs": [],
   "source": [
    "def compile_model(num_bytes, num_filters_tuple, filter_size = 3, padding_type=\"same\", act_function=\"relu\", pooling_type=\"max\", dense_layer_size=16, dropout_rate=0.1, l_rate=0.001, reg='l2', opt_algo='adam'):\n",
    "    \"\"\"\n",
    "    Compiles a deep 2D-CNN model with the given hyperparameters, for a given payload size: `num_bytes`.\n",
    "    \n",
    "    Architecture:\n",
    "    \n",
    "    Conv layer -> Conv layer -> Pooling layer -> Conv layer -> Conv layer -> Pooling layer\n",
    "    ->  Fully connected layer -> Softmax output layer\n",
    "    \n",
    "    Hyperparameter options:\n",
    "    \n",
    "    num_filters_tuple : A 4-tuple with the number of filters for each conv layer\n",
    "    filter_size : an int with the size of the filters (3 -> 3 x 3 filter)\n",
    "    padding_type : either \"same\" or \"valid\"\n",
    "    act_function : options include \"relu\", \"sigmoid\" and \"tanh\"\n",
    "    pooling_type : either \"max\" or \"avg\"\n",
    "    dense_layer_size : an int with the number of neurons in the fully connected layer\n",
    "    dropout_rate : a float with the rate of dropout to be applied to the fully connected layer\n",
    "    l_rate : a float with the learning rate\n",
    "    reg : string with the regularization type e.g. \"l2\"\n",
    "    opt_algo : the optimization algorithm, \"adam\" or \"sgd\"\n",
    "    \n",
    "    Note: `num_bytes` must be a perfect square\n",
    "    \"\"\"  \n",
    "    \n",
    "    if int(sqrt(num_bytes))**2 != num_bytes:\n",
    "      raise Exception(\"`num_bytes` must be a perfect square\")\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # CONVOLUTIONAL LAYER 1\n",
    "    model.add(Conv2D(filters=num_filters_tuple[0], kernel_size=(filter_size,filter_size), input_shape=(int(sqrt(num_bytes)), int(sqrt(num_bytes)), 1), padding=padding_type))\n",
    "    model.add(Activation(act_function))\n",
    "\n",
    "    # CONVOLUTIONAL LAYER 2\n",
    "    model.add(Conv2D(filters=num_filters_tuple[1], kernel_size=(filter_size,filter_size), padding=padding_type))\n",
    "    model.add(Activation(act_function))\n",
    "\n",
    "    # POOLING LAYER 1\n",
    "    if pooling_type == \"avg\":  # strides defaults to pool_size\n",
    "      model.add(AvgPool2D(pool_size=(2, 2)))\n",
    "    elif pooling_type == \"max\":\n",
    "      model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    else:\n",
    "      raise Exception(\"Invalid pooling option entered\")\n",
    "      \n",
    "    # CONVOLUTIONAL LAYER 3\n",
    "    model.add(Conv2D(filters=num_filters_tuple[2], kernel_size=(filter_size,filter_size), padding=padding_type))\n",
    "    model.add(Activation(act_function))\n",
    "\n",
    "     # CONVOLUTIONAL LAYER 4\n",
    "    model.add(Conv2D(filters=num_filters_tuple[3], kernel_size=(filter_size,filter_size), padding=padding_type))\n",
    "    model.add(Activation(act_function))\n",
    "\n",
    "    # POOLING LAYER 2\n",
    "    if pooling_type == \"avg\":  # strides defaults to pool_size\n",
    "      model.add(AvgPool2D(pool_size=(2, 2)))\n",
    "    elif pooling_type == \"max\":\n",
    "      model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    else:\n",
    "      raise Exception(\"Invalid pooling option entered\")\n",
    "\n",
    "    # FLATTEN OUTPUT\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # # FULLY CONNECTED LAYER\n",
    "    model.add(Dense(dense_layer_size, activation=act_function))\n",
    "\n",
    "    # # DROPOUT to prevent overfitting\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # LAST LAYER IS THE CLASSIFIER, THUS 12 POSSIBLE CLASSES\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=reg))\n",
    "\n",
    "    # Optimization algorithm\n",
    "    if opt_algo == 'adam':\n",
    "      opt = tf.keras.optimizers.Adam(learning_rate=l_rate)\n",
    "    elif opt_algo == 'sgd':\n",
    "      opt = tf.keras.optimizers.SGD(learning_rate=l_rate)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcN-0PM6-ne7"
   },
   "source": [
    "# Experiment: Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mSyydAU0Sxsj"
   },
   "source": [
    "Defining grid search hyperparameter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WfHIQO373HT"
   },
   "outputs": [],
   "source": [
    "payload_sizes = [k**2 for k in [i for i in range(0, 40, 4)]]\n",
    "num_filters_tuples = [(32, 32, 32, 32)]\n",
    "l_rates = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "dropout_rates = [0.05, 0.1, 0.2, 0.5]\n",
    "pooling_types = [\"max\"]#, \"avg\"]\n",
    "filter_sizes = [3]\n",
    "padding_types = [\"same\"]\n",
    "# dense_layer_sizes = [16]\n",
    "act_functions=[\"relu\"]\n",
    "regs = ['l2']\n",
    "opt_algos = ['adam']\n",
    "\n",
    "all_hparams = [payload_sizes, num_filters_tuples, l_rates, dropout_rates, pooling_types, filter_sizes, padding_types, act_functions, regs, opt_algos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-21T12:52:36.700824Z",
     "start_time": "2020-09-21T12:52:36.694690Z"
    }
   },
   "source": [
    "Conduct the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ld0_e7b79Aa"
   },
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "  \"\"\"\n",
    "  For each payload size in `payload_sizes`, conduct a grid search over the hyperparameter \n",
    "  options, writing the validation results and model details for each model to a file.\n",
    "  \n",
    "  All trained models are saved as h5 files. \n",
    "  \"\"\"\n",
    " \n",
    "  best_model = None\n",
    "  best_accuracy = 0\n",
    "  best_history = None\n",
    "\n",
    "  EPOCHS = 50\n",
    "  BATCH_SIZE = 32\n",
    "  STOPPING_PATIENCE = 5\n",
    "\n",
    "  STARTING_POINT = 1\n",
    "\n",
    "  with open('../training-results/ExperimentLogs_PayloadSizes.csv', 'w') as log_file:\n",
    "      log_file.write(\"ModelNumber;Timestamp;NumEpochs;ValAccuracy;NumParams;NumBytes;NumFiltersPerLayer;DenseLayerSize;LearningRate;DropoutRate;PoolingType;FilterSize;PaddingType;ActivationFunction;Regularization;OptimizationAlgorithm\\n\")\n",
    "\n",
    "  for model_num, hparam_set in enumerate(list(product(*all_hparams))[0:], start=STARTING_POINT):\n",
    "    # Extract hyperparams for current model from grid search grid\n",
    "    num_bytes, num_filters_tuple, l_rate, dropout_rate, pooling_type, filter_size, padding_type, act_function, reg, opt_algo = hparam_set\n",
    "    dense_layer_size = num_filters_tuple[0]  # set number of dense layer neurons to number of filters of first two conv layers\n",
    "\n",
    "    # Define hyperparameters for the current model \n",
    "    hparams = {\n",
    "        \"num_bytes\" : num_bytes,\n",
    "        \"num_filters_tuple\" : num_filters_tuple,\n",
    "        \"filter_size\" : filter_size, \n",
    "        \"padding_type\" : padding_type, \n",
    "        \"act_function\" : act_function, \n",
    "        \"pooling_type\" : pooling_type, \n",
    "        \"dense_layer_size\" : dense_layer_size, \n",
    "        \"dropout_rate\" : dropout_rate, \n",
    "        \"l_rate\": l_rate,\n",
    "        \"reg\" : reg,\n",
    "        \"opt_algo\" : opt_algo\n",
    "    }\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = preprocess_varying_payloads(df_train, df_test, df_val, num_bytes)\n",
    "\n",
    "    # Compile model and count number of parameters\n",
    "    model = compile_model(**hparams)\n",
    "    num_params = model.count_params()\n",
    "\n",
    "    model_str = f\"{num_bytes}; {num_filters_tuple}; {dense_layer_size}; {l_rate}; {dropout_rate}; {pooling_type}; {filter_size}; {padding_type}; {act_function}; {reg}; {opt_algo}\"\n",
    "    print(f\"Training model {model_num} with {num_params} params - {model_str}\")\n",
    "\n",
    "    # Prevent overfitting with early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=STOPPING_PATIENCE)\n",
    "    # For saving best val accuracy model as an h5 (for test predictions later)\n",
    "    model_check = ModelCheckpoint(f\"../trained-models/Deep-CNN_{model_num}.h5\", monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(42)\n",
    "\n",
    "    # Train model\n",
    "    # Note: one reason val accuracy might be higher than train accuracy during training is because dropout affects training but not validation\n",
    "    history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), callbacks=[early_stop, model_check])\n",
    "    n_epochs = len(history.history['loss'])\n",
    "                   \n",
    "    # Time stamp when model finished training\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    # Extract best validation accuracy at inex 1 (index 0 has the loss)\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    print(f\"Best val accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Store results in log file\n",
    "    with open('../training-results/ExperimentLogs_PayloadSizes.csv', 'a') as log_file:\n",
    "      log_file.write(f\"{model_num};{timestamp};{n_epochs};{val_accuracy};{num_params};{model_str}\\n\")\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "      best_accuracy = val_accuracy\n",
    "      best_model = model\n",
    "      best_history = history\n",
    "\n",
    "  # Return the model with the highest validation accuracy\n",
    "  return best_model, best_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HcyZqJCR79Qy",
    "outputId": "4b03a12b-9f83-4a30-b34c-8514e518c437"
   },
   "outputs": [],
   "source": [
    "best_model, best_history = grid_search()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Experiment2_PayloadSize.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
